# üëª Ghost-Sourcer v6.0
**100% Local AI Resume Screener for Technical Recruiters**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Node.js](https://img.shields.io/badge/Node.js-18%2B-green.svg)](https://nodejs.org/)
[![Privacy](https://img.shields.io/badge/Privacy-100%25%20Local-brightgreen.svg)](#)

---

## üáßüá∑ Portugu√™s

Eu desenvolvi o **Ghost-Sourcer** para realizar triagens t√©cnicas rodando **100% localmente**. Como Recrutador T√©cnico, entendo que a privacidade dos dados dos candidatos √© um pilar inegoci√°vel da nossa profiss√£o. Esta ferramenta permite um processamento especializado diretamente no meu hardware, utilizando o poder do **Llama 3** via **Ollama**.

### üîí Privacidade Total
- **Zero dados na nuvem**: Nenhuma informa√ß√£o sai da sua m√°quina
- **Sem APIs externas**: Todo processamento √© local
- **LGPD/GDPR nativo**: Compliance por design

### üöÄ Por que eu criei esta ferramenta?
* **Privacidade Total**: O curr√≠culo nunca sai da sua m√°quina local.
* **Equival√™ncia Arquitetural**: Vou al√©m do mapeamento de palavras-chave; o agente analisa se as compet√™ncias t√©cnicas s√£o transfer√≠veis entre ecossistemas (ex: AWS ‚Üí GCP).
* **Custo Zero**: Todo o processamento roda via **Ollama** na sua pr√≥pria GPU.

### üõ°Ô∏è Por que IA Local (Edge)?
Em um ecossistema de recrutamento moderno, a soberania de dados √© priorit√°ria. O Ghost-Sourcer foi desenhado para atuar como uma camada de **Edge Computing** para triagem inicial.

* **Ingest√£o Zero-Trust**: Informa√ß√µes sens√≠veis (PII) permanecem em ambiente isolado.
* **Sandbox Privado**: Valide perfis sem tr√¢nsito de dados em redes externas.
* **Mapeamento de Princ√≠pios**: Foco em **princ√≠pios de engenharia**, n√£o apenas keywords.

### üõ†Ô∏è Stack T√©cnica
* **Runtime**: Node.js v18+ com ES Modules
* **Backend**: Express.js
* **AI Engine**: Ollama + Llama 3 (100% local)
* **Document Parsing**: `pdf-parse` para PDFs

### üñ•Ô∏è Hardware Recomendado
* **GPU**: NVIDIA com 8GB+ VRAM (RTX 3060 ou superior)
* **RAM**: 16GB m√≠nimo
* **CPU**: Qualquer processador moderno

---

## üá∫üá∏ English

I built **Ghost-Sourcer** to run technical screenings **100% locally**. As a Tech Recruiter, I recognize that candidate data privacy is a non-negotiable pillar of our field. This tool enables specialized processing by leveraging **Llama 3** via **Ollama** directly on your own hardware.

### üîí Total Privacy
- **Zero cloud data**: No information leaves your machine
- **No external APIs**: All processing is local
- **LGPD/GDPR native**: Compliance by design

### üöÄ Why I Built This
* **Total Privacy**: Resumes never leave your machine.
* **Architectural Equivalence**: Beyond keyword matching - analyzes if skills transfer across ecosystems (e.g., AWS ‚Üí GCP).
* **Zero Cost**: All processing runs via **Ollama** on your local GPU.

### üõ°Ô∏è Why Local Edge AI?
In modern recruiting, data sovereignty is priority. Ghost-Sourcer acts as an **Edge Computing** layer for initial screening.

* **Zero-Trust Data Ingest**: PII stays in an isolated local environment.
* **Private Sandbox**: Validate profiles without external network transit.
* **Engineering-First Mapping**: Focus on **engineering principles**, not just keywords.

### üõ†Ô∏è Tech Stack
* **Runtime**: Node.js v18+ with ES Modules
* **Backend**: Express.js
* **AI Engine**: Ollama + Llama 3 (100% local)
* **Document Parsing**: `pdf-parse` for PDFs

### üñ•Ô∏è Recommended Hardware
* **GPU**: NVIDIA with 8GB+ VRAM (RTX 3060 or better)
* **RAM**: 16GB minimum
* **CPU**: Any modern processor

---

## üì¶ Installation

### Quick Start (Windows)

1. **Install Node.js**
   - Download from [nodejs.org](https://nodejs.org/) (LTS version)
   - Run installer, click Next until done

2. **Install Ollama**
   - Download from [ollama.ai](https://ollama.ai/)
   - Run installer
   - Open terminal and run:
     ```bash
     ollama pull llama3
     ```
   - Wait for download (~4GB)

3. **Setup Ghost-Sourcer**
   ```bash
   git clone https://github.com/marcuscaiado/ghost-sourcer.git
   cd ghost-sourcer
   ```
   - Double-click `SETUP.bat`
   - Wait for dependencies to install

4. **Run**
   - Double-click `START.bat`
   - Browser opens automatically

### Manual Installation (Mac/Linux)

```bash
# Clone repository
git clone https://github.com/marcuscaiado/ghost-sourcer.git
cd ghost-sourcer

# Install dependencies
npm install

# Start Ollama (in separate terminal)
ollama serve

# Pull model (first time only)
ollama pull llama3

# Start server
node server.js

# Open in browser
open http://localhost:3001
```

---

## üöÄ Usage

1. **Paste Job Description** - Include required level, location, skills, experience
2. **Upload Resume PDF** - Drag & drop or click to select
3. **Click Analyze** - Wait 10-30 seconds
4. **Review Results** - Score, verdict, gaps, recommendations

### Scoring System

| Score | Label | Verdict |
|-------|-------|---------|
| 90-100 | UNICORN | ADVANCE |
| 75-89 | STRONG | ADVANCE |
| 60-74 | MAYBE | MAYBE |
| 40-59 | WEAK | REJECT |
| 0-39 | REJECT | REJECT |

---

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Server port | `3001` |
| `OLLAMA_MODEL` | Model to use | `llama3` |

### Using a Different Model

```bash
# Use Mistral instead
OLLAMA_MODEL=mistral node server.js

# Use Llama 3.1
ollama pull llama3.1
OLLAMA_MODEL=llama3.1 node server.js
```

---

## ‚ùì Troubleshooting

### "Ollama is not running"
```bash
# Start Ollama service
ollama serve
```

### "Connection Error" in browser
- Make sure you ran `START.bat` or `node server.js`
- Don't open `index.html` directly from file explorer

### "Model not found"
```bash
# Pull the model
ollama pull llama3
```

### Slow performance
- Ensure GPU drivers are updated
- Check that Ollama is using GPU: `ollama ps`
- Try a smaller model: `OLLAMA_MODEL=llama3:8b`

### PDF not working
- Must be text-based PDF (not scanned image)
- Try re-exporting from original source
- Max file size: 15MB

---

## üîê Privacy Guarantee

Ghost-Sourcer is designed with privacy as the core principle:

- ‚úÖ **No cloud services** - Everything runs locally
- ‚úÖ **No external APIs** - No data leaves your machine
- ‚úÖ **No telemetry** - No usage tracking
- ‚úÖ **No storage** - Resumes are processed in memory only
- ‚úÖ **Open source** - Audit the code yourself

Your candidates' data stays on YOUR machine. Period.

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file.

---

## üë§ Author

**Marcus Caiado**
- LinkedIn: [linkedin.com/in/marcuscaiado](https://linkedin.com/in/marcuscaiado)
- GitHub: [github.com/marcuscaiado](https://github.com/marcuscaiado)

---

## üôè Acknowledgments

- [Ollama](https://ollama.ai/) for making local LLMs accessible
- [Meta](https://llama.meta.com/) for open-sourcing Llama
- The open-source community
